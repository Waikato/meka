\documentclass[11pt]{article}
\usepackage[margin=1.1in]{geometry}
\usepackage{my_symbols}
\usepackage{hyperref}
\newcommand{\MEKA}{Meka}
\newcommand{\MICE}{Mice}
\newcommand{\MOA}{Moa}
\newcommand{\WEKA}{Weka}
\newcommand{\MULAN}{Mulan}
\def\version{{\tt 1.2.1}}

\usepackage{datetime}
\newdateformat{mydate}{\monthname[\THEMONTH] \THEYEAR}

\begin{document}

\title{Tutorial. \framework{\MEKA} \version }

\author{Jesse Read}

\date{\mydate\today}

\maketitle

\begin{center}
	\includegraphics{MEKA.png}\\
		A Multilabel/multitarget Extension to WEKA.\\
		\url{http://meka.sourceforge.net}
\end{center}

\tableofcontents

\pagestyle{empty}
\pagebreak

\section{Introduction}

This is a tutorial for the open source machine learning framework \framework{\MEKA}. \framework{\MEKA} is closely based upon the \framework{\WEKA} framework \cite{WEKA}; providing support for development, running and evaluation of \keyword{multi-label} and \keyword{multi-target} classifiers (which \framework{WEKA} does not).

In the \keyword{multi-label} problem, a data instance may be associated with multiple labels. This is as opposed to the traditional task of single-label classification (\ie multi-class, or binary) where each instance is only associated with a single class label. The multi-label context is receiving increased attention and is applicable to a wide variety of domains, including text, music, images and video, and bioinformatics. A good introduction can be found in \cite{MMD} and \cite{Thesis}.

The multi-label problem is in fact a special case of \keyword{multi-target} learning. In multi-target, or \textit{multi-dimensional} learning, a data instance is associated with multiple target variables, where each variable takes a number of values. In the multi-label case, all variables are binary, indicating label relevance ($1$) or irrelevance ($0$). The multi-target case has been investigated by, for example, \cite{UPM} and \cite{MT}.  

\framework{\MEKA} can also includes \emph{incremental} classifiers suitable for the \keyword{data streams} context. An overview of some of the methods included in \framework{\MEKA} for learning from incremental data streams is given in \cite{MEDS2}.

\framework{\MEKA} is released under the GNU GPL licence. The latest release, source code, API reference, this tutorial, and further information and links to additional material, can be found at the website: \url{http://meka.sourceforge.net}. 

This tutorial applies to \framework{\MEKA} version {\version}. 

\section{Getting Started}

\framework{\MEKA} can be download from: \url{http://sourceforge.net/projects/meka/files/}. This tutorial is written for version \version; and assumes that you have downloaded and extracted the \texttt{meka-release-\version} and that \texttt{meka-\version}, found within, is your current working directory.

\subsection{Requirements}

\framework{\MEKA} requires:

\begin{itemize}
	 \item Java version 1.6 or above
\end{itemize}

%\subsection{Downloading}
\framework{\MEKA} comes bundled with \framework{\WEKA}'s \texttt{weka.jar}, and also \framework{\MULAN}'s \texttt{mulan.jar} for running classifiers from this framework. % If \framework{\WEKA} is already installed on your system, it must be at least version release (\texttt{3.7.X}) to be compatible with \texttt{\MEKA}.
These files are found in the \texttt{lib} directory. See \texttt{lib/README.txt} for version information.


%\framework{\MEKA}'s incremental classification extension (\texttt{mice.jar}) comes packaged in a separate jar file. 

\subsection{Running}
\label{sec:running}

\framework{\MEKA} can be used very easily from the command line. For example, to run the Binary Relevance (BR) classifier on the \textit{Music} dataset; type:
\begin{verbatim}
	java -cp "./lib/*" weka.classifiers.multilabel.BR -t data/Music.arff
\end{verbatim}

If you are on a Microsoft Windows system, you need to use back slashes instead of forward slashes (\texttt{.\textbackslash lib\textbackslash*}). If you add the \texttt{jar} files to the system's \texttt{CLASSPATH}, you do not need to supply the \texttt{-cp} option at runtime. For the remainder of examples in this tutorial we will assume that this is the case.

Since Version 1.2 \framework{\MEKA} has a graphical user interface (GUI). Run this with either the \texttt{run.sh} script (under Linux, OSX) as follows:
\begin{verbatim}
	bash run.sh
\end{verbatim}
Run \texttt{run.bat} instead of you are using Microsoft windows.


%\begin{verbatim}
%	export CLASSPATH=$MEKA/meka.jar:$MEKA/weka.jar:$CLASSPATH
%\end{verbatim}
%
%where \texttt{\$MEKA} is the folder you extracted the software to; or by supplying the classpath directly when running java with :


\section{\label{sec:format}\framework{\MEKA}'s Dataset Format}

\framework{\MEKA} uses \framework{\WEKA}'s ARFF file format. See \url{http://weka.wikispaces.com/ARFF} to learn about this format. \framework{\MEKA} uses multiple attributes -- one for each target or label -- rather than a single class attribute. The \emph{number} of target attributes is specified with either \texttt{-C} or \texttt{-c}; \emph{unlike} in \framework{\WEKA} where the \texttt{-c} flag indicates the position of the \emph{class index}. \framework{\MEKA} uses the reference to the \texttt{classIndex} internally to denote the number of target attributes. %This is important when creating new \framework{\MEKA} classifiers (see Section \ref{sec:extending}).

Since the number of target attributes tends to vary with each dataset, for convenience \framework{\MEKA} allows this option (as well as other dataset options like the train/test split percentage) to be stored in the \texttt{@relation} name of an ARFF file, where a colon (\texttt{:}) is used to separate the dataset name and the options. The following is an example ARFF header for multi-target classification with three target variables and four attributes:

{\small
\begin{verbatim}
@relation 'Example_Dataset: -C 3 -split-percentage 50'

@attribute category {A,B,C,NEG}
@attribute label {0,1}
@attribute rank {1,2,3}
@attribute X1 {0,1}
@attribute X2 {0,1}
@attribute X3 numeric
@attribute X4 numeric

@data
\end{verbatim}
}

Note that the format of the \texttt{label} attribute (binary) is the \emph{only} kind of target attribute in multi-\emph{label} datasets. For more examples of \framework{\MEKA} ARFF files; see the \texttt{data/} directory for several multi-label and multi-target datasets (some of these are in a compressed format).

\framework{\MEKA} can also read ARFF files in the \framework{\MULAN} format where target attributes are the \emph{last} attributes, rather than the first ones. This format can also be read by \framework{\MEKA} by specifying a minus sign `\texttt{-}' before the number of target attributes in the \texttt{-C} option. For example, \texttt{-C -3} will set the \emph{last} \texttt{3} attributes as the target attributes automatically when the file is loaded. Alternatively, the class attributes can be moved using \framework{\WEKA}'s \texttt{Reorder} filter, or in the GUI, as in the following. %weka.filters.unsupervised.attribute.

%Note that the \framework{\MULAN} format expects the target attributes to be indexed \emph{last} rather than the first. Specifying \texttt{-c $-L$} to \framework{\MEKA} will automatically move the last $L$ attributes to the beginning upon loading. 

\subsection{Manipulating Datasets in the GUI}
\label{sec:data.gui}

A good way to set up an ARFF file for multi-dimensional classification is using the GUI. Open an ARFF file with `\textsf{Open}' from the \textsf{File} menu. In the \textsf{Preprocess} tab in the right-hand column (see \Fig{screen:arff}), simply select the attributes you wish to use as class attributes and click the button `\textsf{Use class attributes}'. You can then save this file using `\textsf{Save}' from the \textsf{File} menu, which will also save the \texttt{-C} flag into the \texttt{@relation} tag as described above (displayed under '\textsf{Relation:}' in the GUI), so next time the classes will be set automatically.

The datasets that come with \framework{\MEKA} already come with the \texttt{-C} flag specified correctly, so you do not need to set this information.

You can also run any of \framework{\WEKA}'s filters on the dataset with the \textsf{Choose} button. See the \framework{\WEKA} documentation for more information.

\begin{figure}
	\includegraphics[height=0.75\textwidth]{GUI01.png}
	\caption{\label{screen:arff} \framework{MEKA}'s GUI interface; having loaded the \textit{Music} dataset.}
\end{figure}

\section{Using \framework{\MEKA}}%: Running Experiments

%With any suitable dataset it is possible t\framework{\MEKA} classifiers.
A suitable dataset is the only requirement to begin running experiments with \framework{\MEKA}.

\subsection{Command Line Interface}

With the exception of the different use of the \texttt{-c} flag (see the previous section), many of \framework{\WEKA}'s command line options for evaluation work identically in \framework{\MEKA} too. You can obtain a list of them by running any classifier with the \texttt{-h} flag, for example: \texttt{java weka.classifiers.multilabel.BR -h} displays the following:
	 
{\small
\begin{verbatim}
Evaluation Options:

-h
        Output help information.
-t <name of training file>
        Sets training file.
-T <name of test file>
        Sets test file.
-x <number of folds>
        Do cross-validation with this many folds.
-p
        Specify a range in the dataset (@see weka.core.Range)
-R
        Randomise the dataset (done after a range is removed, but before the 
        train/test split)
-split-percentage <percentage>
        Sets the percentage for the train/test set split, e.g., 66.
-split-number <number>
        Sets the number of training examples, e.g., 800.
-i
        Invert the specified train/test split
-s <random number seed>
        Sets random number seed.
-threshold <threshold>
        Sets the type of thresholding; where 
            'PCut1' automatically calibrates a threshold (the default); 
            'PCutL' automatically calibrates one threshold for each label; and 
            any double number, e.g. '0.5', specifies that threshold.
-C <number of target attributes>
        Sets the number of target attributes to expect (indexed from the beginning).
-f <results_file>
        Specify a file to output results and evaluation statistics into.
\end{verbatim}
}

The only required options are \texttt{-t} to specify the dataset, and \texttt{-C} to specify the number of target attributes; the latter is typically included within the dataset, as explained in the previous section. 

Below this output, we also see the output for \texttt{Classifier Options}:

{\small
\begin{verbatim}
Classifier Options:

-D
        If set, classifier is run in debug mode and
        may output additional info to the console
-W
        Full name of base classifier.
        (default: weka.classifiers.rules.ZeroR)
\end{verbatim}
}

which in this case (for \texttt{java weka.classifiers.multilabel.BR}) are not very extensive. However, to get decent results with this classifier, we will have to specify a more competitive \emph{base classifier} with the \texttt{-W} option, for example Naive Bayes. To run this on the \textit{Music} data, we would type\footnote{If typed on one line, the bar `\texttt{\textbackslash}' should be omitted} on the command line:

\begin{verbatim}
java weka.classifiers.multilabel.BR -t data/Music.arff \
  -W weka.classifiers.bayes.NaiveBayes
\end{verbatim}

\subsection{Graphical User Interface}

The CLI is the most powerful way to work with \framework{\MEKA}, but the GUI is a good way to get started. Refer to \Sec{sec:running} on how to open the GUI. Once opened, you will see three tabs: \textsf{Preprocess}, \textsf{Classify}, \textsf{Visualize}. The following process will guide you through a simple experiment.

%Again, to run \framework{\MEKA}'s GUI, simply type \texttt{ant run} from the X directory, or run either the \texttt{run.sh} (under Linux) or \texttt{run.bat} (under Microsoft windows) scripts in the \texttt{scripts/} folder. 



\begin{enumerate}
	\item Load a dataset file using \textsf{Open} from the file menu. %See \Sec{sec:data.gui} for information on preprocessing the datasets.
	\item Click on the \textsf{Classify} tab.
	\item \textsf{Choose} a multi-label or multi-target classifier and (in most cases) an appropriate \framework{\WEKA} base classifier, as well as its options. For \framework{\MEKA}'s meta classifiers, you will need to choose a \framework{\MEKA} base classifier, and a single-label \framework{\WEKA} base classifier for this classifier. See, for example, \Fig{screen:eval}, using Bagging of Classifier Chains with SMO.
	\item In the \textsf{Evaluation} panel you configure what type of evaluation you want to do, and some of the options given in the previous section are available here. For example, a 50/50 train/test split, as being specified in \Fig{screen:split}.
	\item When you click \textsf{Start} the experiment will be run. When finished, the result will appear in the \textsf{History} panel; or multiple results in the case of incremental validation. This is the same output as would be seen on the command line, and explained in the following section.
	%\item You can export results to text, or copy of paste it.
	\item Optionally, you can click on the \textsf{Visualize} tab and visualize the results.
\end{enumerate}




\begin{figure}
	\includegraphics[height=0.60\textwidth]{GUI02.png}
	\caption{\label{screen:eval} \framework{MEKA}'s GUI interface; setting Bagging of Classifier Chains with SMO.}
\end{figure}


\begin{figure}
	\includegraphics[height=0.60\textwidth]{GUI03.png}
	\caption{\label{screen:split} \framework{MEKA}'s GUI interface; setting a train/test split.}
\end{figure}

\subsection{\label{sec:evaluation}Evaluation}

Running a BR classifier with Naive Bayes on the \textit{Enron} data will output the following:

{\small
\begin{verbatim}
Classifier_name : weka.classifiers.multilabel.BR
 Classifier_ops : [-W, weka.classifiers.bayes.NaiveBayes, --, , , ]
Classifier_info : 
   Dataset_name : Music
      Threshold : 0.9974578524138343
           Type : ML

              N : 237
              L : 6    
       Accuracy : 0.436
         H_loss : 0.255
          H_acc : 0.745
    Exact_match : 0.215
   ZeroOne_loss : 0.785
      One_error : 0.414
       LogLossD : 7.302
       LogLossL : 2.972
      Precision : 0.629
         Recall : 0.564
       F1_micro : 0.594
     F1_macro_D : 0.508
     F1_macro_L : 0.551
   EmptyVectors : 0.177
     LCard_pred : 1.785
     LCard_real : 1.992

        N_train : 355.0
         N_test : 237.0
    LCard_train : 1.7887323943661972
     LCard_test : 1.9915611814345993
     Build_time : 0.148
      Test_time : 0.118
     Total_time : 0.266

\end{verbatim}
}

Most of these measures are described in \cite{Thesis,ECC2,MMD}. The most common measures in the multi-label literature are \textit{Hamming Loss} (\texttt{H\_loss}), which is the accuracy for each label, averaged across all labels; \textit{Exact Match} (\texttt{Exact\_match}), which is the is the accuracy of each \emph{example} -- where all label relevances must match exactly for an example to be correct; and \textit{Accuracy} (\texttt{Accuracy}), which is neither as strict as Exact Match nor as `easy' as Hamming Loss.

%\subsection{Thresholds}

Note that a \texttt{Threshold} has been calibrated automatically; to minimise the difference between the label cardinality of the training set and the predictions on the test set; a practice described in \cite{ECC2}. To calibrate a threshold for \emph{each} label, add the \texttt{-threshold PCutL} option\footnote{Note: this was \texttt{-T C} in previous versions of \framework{\MEKA}}. This gives a vector of thresholds which, in this case, increases \texttt{Accuracy} slightly (to \texttt{0.456}). Different thresholds are calculated for different methods and datasets.

%\begin{verbatim}
%          Threshold : [0.29971988795518206, 0.26330532212885155, \
%			  0.4257703081232493, 0.22128851540616246, 0.23809523809523808, \
%			  0.3473389355742297]
%\end{verbatim}

\framework{\MEKA} also supports \emph{cross validation}; for example:
\begin{verbatim}
java weka.classifiers.multilabel.BR -x 10 -R -t ~/data/Music.arff \
  -W weka.classifiers.bayes.NaiveBayes
\end{verbatim}
conducts 10 fold cross validation on a randomised version of the \textit{Music.arff} data and outputs the average results across all folds with standard deviation. %Note that using the \texttt{-f} option in this case to save output to a file will output only the results of the validation; which can be useful for compiling results later.

Sometimes it can be useful to analyse the actual predictions made at test time (for example if you wish to use an evaluation metric not included in \framework{\MEKA}). \framework{\MEKA} can produce plain-text files with the option \texttt{-f <file name>}; for example:
\begin{verbatim}
java weka.classifiers.multilabel.BR -t data/Music.arff \ 
  -f BR-NB.meka \
  -W weka.classifiers.bayes.NaiveBayes
\end{verbatim}
which produces the plain-text file \texttt{BR-NB.meka}. This provides a way to analyse individual classifications and evaluate other software with \framework{\MEKA}'s evaluation framework. Note that when cross validation (\texttt{-x}) is used, one file will be created for each fold, e.g., \texttt{BR-NB.meka.0}, \ldots, \texttt{BR-NB.meka.4} for a 5-fold validation. The results can be recalculated for any of these files with, e.g.:
\begin{verbatim}
	java weka.core.Result -f BR-NB.meka
\end{verbatim}
Or, if you used cross validation, with:
\begin{verbatim}
	java weka.core.Result -f BR-NB.meka -x 5
\end{verbatim}

More examples are given in the following subsection.

\subsection{Examples} 

%\paragraph{Multi-label}

%The methods used in the following examples are detailed in papers papers detailing these methods are available here.

\paragraph{Binary Relevance} (BR) On the \textit{Music} data, loading from two separate sets, using Naive Bayes as a base classifier, calibrating a separate threshold automatically for each label: 
\begin{verbatim}
java weka.classifiers.multilabel.BR \
  -t data/Music_train.arff \
  -T data/Music_test.arff \
  -threshold PCutL \
  -W weka.classifiers.bayes.NaiveBayes
\end{verbatim}

\paragraph{Ensembles of Pruned Sets} (EPS; see \cite{EPS}) With 10 ensemble members (the default) on the \textit{Enron} dataset with Support Vector Machines as the base classifier; each \texttt{PS} model is set with \texttt{N=1} and \texttt{P} to a random selection of \texttt{\{1,2,3,4,5\}}:

\begin{verbatim}
java weka.classifiers.multilabel.meta.EnsembleML \
  -t data/Yeast.arff \
  -W weka.classifiers.multilabel.PS -- \
    -P 1-5 -N 1 -W weka.classifiers.functions.SMO
\end{verbatim}

\paragraph{Ensembles of Classifier Chains} (ECC; see \cite{ECC2}) With 50 ensemble members (\texttt{-I 50}), and some textual output (\texttt{-D}) on the \textit{Enron} dataset with Support Vector Machines as a base classifier:
\begin{verbatim}
java weka.classifiers.multilabel.meta.BaggingML -I 50 -P 100 -D \
  -t data/Enron.arff -W weka.classifiers.multilabel.CC -- \
    -W weka.classifiers.functions.SMO
\end{verbatim}

\paragraph{Mulan Classifier} (\texttt{RAkEL} see \cite{RAKEL}) With parameters \texttt{\texttt{k=3}, \texttt{m=2C}} where \texttt{C} is the number of labels (these options are hardwired; you need to edit \texttt{MULAN.java} to specify new parameter configurations) on the \textit{Scene} dataset with Decision Trees as the base classifier (remember {\texttt{mulan.jar} must be in the classpath}):
\begin{verbatim}
java weka.classifiers.multilabel.MULAN -t data/Scene.arff \ 
  -S RAkEL2 -W weka.classifiers.trees.J48
\end{verbatim}

%\paragraph{Cross Validation} the following carries out cross validation on ECC using Logistic Regression as a base classifier, on the \textit{Music} data.

%\begin{verbatim}
%java weka.classifiers.multilabel.meta.BaggingML \
%  -x 10 -R -t data/Music.arff \
%  -I 10 -W weka.classifiers.multilabel.CC -- \
%  -W weka.classifiers.functions.Logistic
%\end{verbatim}

\paragraph{Incremental Classification: Ensembles of Binary Relevance} (see \cite{ECC2,MEDS2}) With 10 ensemble members (default) on the \textit{Enron} dataset with \texttt{NaiveBayesUpdateable} as a base classifier; using over 20 evaluation windows:

\begin{verbatim}
java weka.classifiers.multilabel.meta.EnsembleMLUpdateable -B 20\
  -t data/Enron.arff \
  -W weka.classifiers.multilabel.BRUpdateable -- \
    -W weka.classifiers.bayes.NaiveBayesUpdateable
\end{verbatim}

Evaluating incremental classifiers will carry out evaluation and display statistics for the data over $\texttt{B}-1$ evaluation windows (an initial window is used for the initial training; making \texttt{B} windows in total). %Note that the \framework{\MOA} framework \cite{MOA} for evaluating incremental classifiers is much more sophisticated; and a new release will include a wrapper to \framework{\MEKA}. 

\paragraph{Multi-target: Ensembles of Class Relevance} (see \cite{UPM}) The multi-target version of the Binary Relevance classifier) on the \textit{solar flare} dataset with Logistic Regression as a base classifier under $5$-fold cross-validation:
\begin{verbatim}
java weka.classifiers.multitarget.meta.BaggingMT -x 10 -R \
  -t data/solar_flare.arff \
  -W weka.classifiers.multitarget.CR -- \
    -W weka.classifiers.functions.Logistic
\end{verbatim}

%\begin{verbatim}
%java -cp meka.jar:weka.jar weka.classifiers.multitarget.meta.BaggingMT -x 5 -R -t data/solar_flare.arff -W weka.%classifiers.multitarget.C    C -- -W weka.classifiers.functions.Logistic
%\end{verbatim}

\section{\label{sec:extending}Extending \framework{\MEKA}}%: Writing New Classifiers

The source code is available in the release (\texttt{meka-src-\version-jar}). You can also check out the latest SVN repository from \url{SourceForge.net} \textsf{Code}; see \url{https://sourceforge.net/p/meka/code/} for details. 

Writing \framework{\MEKA} classifiers involves writing regular \framework{\WEKA} classifiers that extend either the \texttt{MultilabelClassifier} or \texttt{MultiTargetClassifier} class, and expect the \texttt{classIndex()} of \texttt{Instance}s and \texttt{Instances}s to indicate the number of target attributes (indexed at the beginning) rather than the class index (as explained in Section \ref{sec:format}). 

The easiest way to extend \framework{\MEKA} is to create your classifier within within the existing \framework{\MEKA} folder hierarchy and recompile a new jar using Apache ant by simply by typing:
\begin{verbatim}
	ant jar
\end{verbatim}

The following is an example of a functioning (but extremely minimalistic) classifier, \texttt{TestClassifier}, that predicts $0$-relevance for all labels:

{\small
\begin{verbatim}
package weka.classifiers.multilabel;
import weka.core.*;

public class TestClassifier extends MultilabelClassifier {
	
    public void buildClassifier(Instances D) throws Exception {
        testCapabilities(D);
        int C = D.classIndex();
    }
    
    public double[] distributionForInstance(Instance x) throws Exception {
        int C = x.classIndex();
       	return new double[C];
    }
    
    public static void main(String args[]) {
        MultilabelClassifier.runClassifier(new TestClassifier(),args);
    }
}
\end{verbatim}
}

This shows how easy it is to create a new classifier. However, for more useful examples see the source code of existing \framework{\MEKA} classifiers. The \texttt{testCapabilities(D)} line is optional but highly recommended. Note that the \texttt{distributionForInstance} method returns a \texttt{double[]} array exactly like in \framework{\WEKA}. However, whereas in \framework{\WEKA}, there is one value in the array for each possible value of the single target attribute, in \framework{\MEKA} this function returns an array of $C$ values, where $C$ is the \emph{number} of target attributes, and the $j$th value of the array is the \emph{value} corresponding to the $j$th target attribute.

\subsection{Building Classifiers}

In the \texttt{buildClassifier(Instances)} method, you build your classifier. Here is where you can take advantage of all of \WEKA's libraries. You can use any \WEKA classifier to your needs. The \texttt{m\_Classifier} variable is already available for this, which \textit{already contains} the \WEKA{} classifier you specify on the command line. You can simply do:
\begin{verbatim}
    public void buildClassifier(Instances D) throws Exception {
        testCapabilities(D);
        int C = D.classIndex();
        D.setClassIndex(0);
        m_Classifier.buildClassifier(D);
    }
\end{verbatim}
to train a classifier to learn the first label of your data (using the other labels, and all other input-space feature attributes). So if you then run on the command line
\begin{verbatim}
    java weka.classifiers.multilabel.TestClassifier -t data/Music.arff \
        -W weka.classifiers.functions.SMO
\end{verbatim}
an instantiation of \texttt{SMO} will already be be available in \texttt{m\_Classifier}. You can also do this explicitly with
\begin{verbatim}
...
    m_Classifier = new SMO();
    m_Classifier.buildClassifier(D);
...
\end{verbatim}

\subsection{Classifying New Instances}

In the multi-label case, for a test \texttt{Instance x}, the \texttt{double[]} array returned by the method \texttt{distributionForInstance(x)} might contain the $0/1$ label relevances, for example (assuming \texttt{-C 5}):
\begin{verbatim}
	[0.0, 0.0, 1.0, 1.0, 0.0]
\end{verbatim} 
or it might contain posterior probabilities / prediction confidences / votes for each label, for example:
\begin{verbatim}
	[0.1, 0.0, 0.9, 0.9, 0.2]
\end{verbatim} 
where clearly the third and fourth labels are most relevant. Under a threshold of $0.5$ the final classification for \texttt{x} would be \texttt{[0,0,1,1,0]}. \framework{\MEKA} will by default automatically calibrate a threshold to convert all values into $0/1$ relevances like these (see Section \ref{sec:evaluation}). 

%\subsection{Multi-target Classifiers}

In the multi-target case, the \texttt{double[]} values returned by the method \texttt{distributionForInstance} must indicate the \emph{relevant class value}; for example (assuming \texttt{-C 3}): 
\begin{verbatim}
	[3.0, 1.0, 0.0]
\end{verbatim} 
If this were the dataset exemplified in \ref{sec:format}, this classification would be \texttt{C}, \texttt{1}, and \texttt{1} for the class attributes \texttt{category}, \texttt{label}, and \texttt{rank}, respectively.

Note that no threshold is calibrated. However, any associated voting or probabilistic values may be stored in the following $\texttt{C+1},\ldots,\texttt{2C}$ values; for example (again assuming \texttt{-C 6}):
\begin{verbatim}
	[3.0, 1.0, 0.0, 0.5, 0.9, 0.9]
\end{verbatim} 
where \texttt{C} is predicted as the value of the first target attribute with confidence $0.9$, and so on. However these values are currently only for use at classification time (for example the voting scheme of an ensemble method, see \texttt{weka.classifiers.multitarget.BaggingMT}); and not taken into account for evaluation. Note also that we intend to deprecate this method in the future, so avoid if possible.

\subsection{Incremental Classifiers}

\framework{\MEKA} comes with incremental versions of many classifiers, as well as incremental evaluation methods. Incremental classifiers implement \framework{\WEKA}'s \texttt{UpdatebleClassifier} interface and therefore must implement the \texttt{updateClassifier(Instance)} method. The following extends \texttt{TestClassifier} for incremental learning.

{\small
\begin{verbatim}
package weka.classifiers.multilabel;
import weka.core.*;

public class TestClassifierUpdateable extends TestClassifier 
    implements UpdateableClassifier{
	
    public void updateClassifier(Instance x) throws Exception {
        int L = D.classIndex();
    }
    
    public static void main(String args[]) {
        IncrementalEvaluation.runExperiment(new TestClassifierUpdateable(),args);
    }
}
\end{verbatim}
}

Note that the \texttt{IncrementalEvaluation} class is called for evaluation in this case; see Section \ref{sec:evaluation}. The \framework{\MOA} framework \cite{MOA} for learning in data streams contains a number of incremental classifiers that \WEKA{} does not, for example Hoeffding trees. It is included in \framework{\MEKA}, and you can run these classifiers using \WEKA's \texttt{MOA} meta classifier (wrapper), e.g., 
\begin{verbatim}
    java weka.classifiers.multilabel.BRUpdateable -D -t data/Music.arff \
        -W weka.classifiers.meta.MOA -- -B moa.classifiers.trees.HoeffdingTree
\end{verbatim}

Note that \framework{\MOA} now also supports \framework{\MEKA} classifiers via a wrapper class; and is currently being developed to support a range of incremental multi-label classification and evaluation for data streams.

\section{Getting Help / Reporting Bugs / Contributing}

If you need help with \framework{\MEKA}, you can post your problem on \MEKA's \textsf{Mailing List}: \url{http://sourceforge.net/p/meka/mailman/}.

If you have found a bug with \framework{\MEKA}, you can report in via the \textsf{Tracker}  of \framework{\MEKA}'s \url{SourceForge.net} site: \url{http://sourceforge.net/p/meka/bugs/}.

If you would like to contribute to \framework{\MEKA}, such as adding new classifiers, please get in touch with the developers.

More more information (such as contact information) can be found at the \framework{\MEKA} website:
\url{http://meka.sourceforge.net}.

\appendix

\section{Methods Implemented in \MEKA}
 
Below is a list of the major methods supported in \framework{\MEKA}, along with their abbreviations (in some cases methods are known by more than one name), and the class name (given from the \texttt{classifiers} directory). Problem transformation methods expect a \texttt{-W} option. For example, to run classifier chains:
\begin{verbatim}
	java weka.classifiers.multilabel.meta.BaggingML -P 100 \
		-W weka.classifiers.multilabel.CC -- -W weka.classifiers.functions.SMO	
\end{verbatim}
and to run CLR:
\begin{verbatim}
	java weka.classifiers.multilabel.MULAN -S CLR -W weka.classifiers.functions.SMO	
\end{verbatim}
Other parameters are mostly set to the default found in the literature where the method was introduced. The methods have been grouped approximately together. Citations are included within the \texttt{TechnicalInformation} of the source code files. $U$ indicates that an \texttt{Updateable} version is available. $M$ indicates that a multi-target version (or can be used directly) is available.\\
{
{\par \vspace{2mm}}
\begin{tabular}{ll}
	\hline
	\textbf{Algorithm}               & \textbf{Class Name} \\
	\hline
	Majority Labelset [$U$,$M$] & \texttt{MajorityLabelset} \\
	\hline
	Binary Relevance (BR) [$U$,$M$] & \texttt{BR} \\
	Classifier Chains (CC) [$U$,$M$] & \texttt{CC} \\
	Ensembles of CC (ECC)  [$U$,$M$] & \texttt{meta.BaggingML -P 100 -W CC} \\
	Ensembles of CC `quick' (ECCq) [$U$,$M$] & \texttt{meta.RandomSubspaceML -W CCq} \\
	Probabilistic Classifier Chains (PCC) [$M$] & \texttt{PCC} \\
	Monte Carlo Optimization of CC (MCC) [$M$] & \texttt{MCC} \\
	\hline
	Ranking + Threshold [$M$] (RT, a.k.a. PT5)  & \texttt{RT} \\
	\hline
	Fourclass Pairwise (FW, a.k.a. PW)  & \texttt{FW} \\
	Calibrated Label Ranking [R] & \texttt{MULAN -S CLR} \\ 
	\hline
	Learning EM-style from unlabeled examples  & \texttt{meta.EM} \\ 
	\hline
	Conditional Dependency Networks [$M$] & \texttt{CDN} \\ 
	%Deep Belief Network            & \texttt{DBN} \\
	\hline
	Label Combination (LC, a.k.a. LP) & \texttt{LC} \\ 
	Random $k$-labEL Sets (RA$k$EL) & \texttt{MULAN -S RAkEL1} \\ 
	Pruned Problem Transformation (PPT)  & \texttt{PSt} \\
	Pruned Sets (PS)               & \texttt{PS} \\
	Ensembles of Pruned Sets (EPS  & \texttt{meta.EnsembleML -W PS} \\
	Nearest Set Replacement (NSR) [$M$]  & \texttt{meta.EnsembleML -W PS} \\
	\hline
\end{tabular}
}

\include{bibliography}

\end{document}
